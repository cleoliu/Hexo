---
title: 即時股價追蹤與分析App
date: 2025-08-13 18:45:09
subtitle: 即時股價追蹤與分析App
categories:
  - Web Development
tags:
  - python
  - web-scraping
  - tutorial
  - troubleshooting

cover_index: https://res.cloudinary.com/dsvl326mi/image/upload/v1755081908/blog_covers/icon-192x192_o5xyax.png
---

# 深入解析與解決網頁內容抓取中的 403 Forbidden 錯誤

## 導言

在進行網頁內容抓取（Web Scraping）時，開發者經常會遇到各種 HTTP 狀態碼錯誤，其中最常見且令人困擾的之一便是 `403 Forbidden` 錯誤。當您嘗試透過程式碼（例如 Python 的 `requests` 函式庫）訪問某個網址時，如果伺服器回傳 `403 Forbidden`，這表示伺服器理解了您的請求，但拒絕授權您訪問所請求的資源。這通常是網站為了防止自動化爬蟲、惡意行為或保護內容而實施的安全措施。

本教學文章旨在深入探討 `403 Forbidden` 錯誤的常見原因，並提供一系列實用的解決方案與程式碼範例，幫助您成功克服這一障礙，合法且有效地獲取網頁內容。我們將從基礎的 HTTP 請求頭模擬，到更進階的會話管理和代理伺服器使用，逐步引導您掌握解決此類問題的技巧。

## 前置需求

在開始實作之前，請確保您的環境符合以下要求：

*   **作業系統**：Windows, macOS, 或 Linux
*   **程式語言**：Python 3.6 或更新版本
*   **Python 套件**：
    *   `requests`：用於發送 HTTP 請求
    *   `BeautifulSoup4` (可選)：用於解析 HTML 內容
*   **開發環境**：
    *   已安裝 Python 及 `pip` 套件管理器。
    *   建議使用虛擬環境 (Virtual Environment) 來管理專案依賴。

**安裝所需套件**：
打開您的終端機或命令提示字元，執行以下命令：

```bash
pip install requests beautifulsoup4
```

## 實作步驟

### 1. 了解 403 Forbidden 錯誤

`403 Forbidden` 錯誤表示伺服器已理解您的請求，但拒絕提供訪問權限。這與 `404 Not Found`（資源不存在）或 `401 Unauthorized`（需要身份驗證）不同。導致 403 錯誤的常見原因包括：

*   **缺少或不正確的 User-Agent 標頭**：許多網站會檢查請求中的 `User-Agent` 標頭，如果它看起來不像一個標準瀏覽器，就會拒絕訪問。
*   **IP 地址被封鎖**：您的 IP 地址可能因為頻繁請求或其他原因被網站暫時或永久封鎖。
*   **缺少 Referer 標頭**：某些網站會檢查請求來源（Referer），以確保請求是從合法頁面發出的。
*   **缺少 Cookie 或會話資訊**：需要登入或維護會話狀態的網站會拒絕沒有相關 Cookie 的請求。
*   **網站的機器人防護機制**：如 CAPTCHA、WAF (Web Application Firewall) 等。
*   **robots.txt 規則**：雖然 `robots.txt` 僅是協定，但有些伺服器會嚴格遵守並拒絕被 `Disallow` 的路徑。

### 2. 初步嘗試與錯誤再現

首先，我們來嘗試一個基本的 `requests.get()` 請求。以您提供的 Claude AI 分享連結為例，這類連結通常有嚴格的訪問控制，直接訪問很可能觸發 403 錯誤。

```python
import requests

# 嘗試訪問一個已知會觸發 403 錯誤的網址（例如：嚴格保護的分享連結）
# 注意：以下網址僅為演示，實際操作中，此類網址極難透過簡單爬蟲獲取內容。
url = "https://claude.ai/share/e49c140e-4727-4802-ab74-2b24c8e1e3a6"

try:
    response = requests.get(url)
    response.raise_for_status()  # 如果狀態碼不是 200，則拋出 HTTPError
    print(f"成功獲取網頁內容，狀態碼：{response.status_code}")
    print(response.text[:500]) # 打印部分內容
except requests.exceptions.HTTPError as e:
    print(f"錯誤：無法獲取網址內容：{e}")
    print(f"狀態碼：{e.response.status_code}")
    print(f"回應頭：{e.response.headers}")
except requests.exceptions.RequestException as e:
    print(f"請求發生錯誤：{e}")

```

執行上述程式碼，您很可能會看到類似以下的輸出：

```
錯誤：無法獲取網址內容：403 Client Error: Forbidden for url: https://claude.ai/share/e49c140e-4727-4802-ab74-2b24c8e1e3a6
狀態碼：403
回應頭：... (伺服器可能返回一些關於拒絕的資訊)
```

這證實了 403 錯誤的發生。接下來，我們將嘗試不同的方法來解決它。

### 3. 添加 User-Agent 標頭

這是解決 403 錯誤最常見且有效的方法。許多網站會檢查 `User-Agent` 標頭，以判斷請求是否來自合法的瀏覽器。如果沒有提供或提供了一個不尋常的 `User-Agent`，伺服器可能會拒絕請求。

**如何獲取您的瀏覽器 User-Agent？**
1.  打開您的瀏覽器 (Chrome, Firefox 等)。
2.  按下 `F12` 開啟開發者工具。
3.  切換到 "Console" (控制台) 或 "Network" (網路) 選項卡。
4.  在控制台中輸入 `navigator.userAgent` 並按下 Enter。
5.  在 "Network" 選項卡中，重新載入頁面，選擇任意一個請求，查看其 "Request Headers" 中的 `User-Agent`。

```python
import requests

url = "https://example.com/some-protected-page" # 替換為您要抓取的目標網址
# 建議使用您自己瀏覽器的 User-Agent，以下為一個常見的 Chrome User-Agent 範例
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}

try:
    response = requests.get(url, headers=headers)
    response.raise_for_status()
    print(f"成功獲取網頁內容，狀態碼：{response.status_code}")
    print(response.text[:500])
except requests.exceptions.HTTPError as e:
    print(f"錯誤：無法獲取網址內容：{e}")
    print(f"狀態碼：{e.response.status_code}")
except requests.exceptions.RequestException as e:
    print(f"請求發生錯誤：{e}")

```

### 4. 模擬完整瀏覽器請求 (添加更多標頭)

如果僅僅添加 `User-Agent` 不足以解決問題，這表示網站可能檢查了更多的 HTTP 請求頭。您可以嘗試模擬一個更完整的瀏覽器請求，包含 `Accept`、`Accept-Language`、`Referer`、`Connection` 等。

```python
import requests

url = "https://example.com/another-protected-page" # 替換為您要抓取的目標網址
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8",
    "Accept-Language": "zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7",
    "Referer": "https://www.google.com/", # 模擬從 Google 點擊過來
    "Connection": "keep-alive",
    "Upgrade-Insecure-Requests": "1"
}

try:
    response = requests.get(url, headers=headers)
    response.raise_for_status()
    print(f"成功獲取網頁內容，狀態碼：{response.status_code}")
    print(response.text[:500])
except requests.exceptions.HTTPError as e:
    print(f"錯誤：無法獲取網址內容：{e}")
    print(f"狀態碼：{e.response.status_code}")
except requests.exceptions.RequestException as e:
    print(f"請求發生錯誤：{e}")

```

### 5. 使用 Session 對象保持狀態 (處理 Cookie 和會話)

對於需要登入或維護會話狀態的網站，單次請求可能不足以獲取內容。`requests.Session` 對象可以幫助您在多個請求之間保持 Cookie，模擬瀏覽器的會話行為。

```python
import